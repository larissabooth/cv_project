{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/larissabooth/cv_project/blob/main/evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqVM6wqc3k3-",
        "outputId": "fe9274b9-25aa-4c32-f368-75137059745b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
        "\n",
        "# All rights reserved.\n",
        "\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import signal\n",
        "import sys\n",
        "import time\n",
        "import urllib\n",
        "\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms\n",
        "import torch\n",
        "\n",
        "sys.path.append(\"/content/drive/My Drive/computer_vision_project/vicreg\")\n",
        "\n",
        "import resnet\n",
        "print(resnet.BasicBlock)\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "LSwD6err3tMt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "595ef28b-d441-4fd1-e05c-cdd0e8c48e63"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'resnet.BasicBlock'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Network configurations\n",
        "\n",
        "%cd \"/content/drive/My Drive/computer_vision_project/vicreg\"\n",
        "\n",
        "#Data\n",
        "data_dir = \"/content/drive/My Drive/computer_vision_project/Kitchener_torch\"\n",
        "train_percent = 10 #\"size of traing set in percent\"\n",
        "\n",
        "# Checkpoint\n",
        "ckpt_file = Path(\"checkpoint.pth\")\n",
        "pretrained = \"./checkpoints/lincls/resnet50.pth\" #path to pretrained model\n",
        "exp_dir = Path(\"./checkpoints/lincls\") #path to export directory\n",
        "print_freq = 100 #number of steps before printing\n",
        "\n",
        "# Model\n",
        "arch = \"resnet50\"\n",
        "\n",
        "# Optim\n",
        "epochs = 10\n",
        "batch_size = 128\n",
        "lr_backbone = 0.0 #\"backbone base learning rate\"\n",
        "lr_head = 0.3 #\"classifier base learning rate\"\n",
        "weight_decay = 1e-6\n",
        "weights = \"freeze\" #(\"finetune\", \"freeze\")\n",
        "\n",
        "# Running\n",
        "workers= 1 #\"number of data loader workers\"\n",
        "rank = 0\n",
        "\n",
        "#Stats file\n",
        "stats_file =\"stats/stats_file.json\""
      ],
      "metadata": {
        "id": "IqF1zEYB4rGY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4faaa4d8-8776-4f5d-e6d3-a7d08048bcb8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1RST5HayuSWDl47eVsz8vHQpNYKmjc800/computer_vision_project/vicreg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self, name, fmt=\":f\"):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = \"{name} {val\" + self.fmt + \"} ({avg\" + self.fmt + \"})\"\n",
        "        return fmtstr.format(**self.__dict__)"
      ],
      "metadata": {
        "id": "bieTW6P1HJWH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Z-Pa58iE3c9I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ea1da04-92eb-492d-c5a6-b810ac4fcf7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1RST5HayuSWDl47eVsz8vHQpNYKmjc800/computer_vision_project/vicreg\n"
          ]
        }
      ],
      "source": [
        "#@title Load model\n",
        "\n",
        "backbone, embedding = resnet.__dict__[arch](zero_init_residual=True)\n",
        "state_dict = torch.load(pretrained, map_location=\"cpu\")\n",
        "if \"model\" in state_dict:\n",
        "    state_dict = state_dict[\"model\"]\n",
        "    state_dict = {\n",
        "        key.replace(\"module.backbone.\", \"\"): value\n",
        "        for (key, value) in state_dict.items()\n",
        "    }\n",
        "backbone.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "head = nn.Linear(embedding, 26)\n",
        "head.weight.data.normal_(mean=0.0, std=0.01)\n",
        "head.bias.data.zero_()\n",
        "model = nn.Sequential(backbone, head)\n",
        "model.to(device)\n",
        "\n",
        "if weights == \"freeze\":\n",
        "    backbone.requires_grad_(False)\n",
        "    head.requires_grad_(True)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "param_groups = [dict(params=head.parameters(), lr=lr_head)]\n",
        "if weights == \"finetune\":\n",
        "    param_groups.append(dict(params=backbone.parameters(), lr=lr_backbone))\n",
        "optimizer = optim.SGD(param_groups, 0, momentum=0.9, weight_decay=weight_decay)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
        "\n",
        "# automatically resume from checkpoint if it exists\n",
        "if (exp_dir / ckpt_file).is_file():\n",
        "    ckpt = torch.load(exp_dir / ckpt_file, map_location=\"cpu\")\n",
        "    start_epoch = ckpt[\"epoch\"]\n",
        "    best_acc = ckpt[\"best_acc\"]\n",
        "    model.load_state_dict(ckpt[\"model\"])\n",
        "    optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
        "    scheduler.load_state_dict(ckpt[\"scheduler\"])\n",
        "else:\n",
        "    start_epoch = 0\n",
        "    best_acc = argparse.Namespace(top1=0, top5=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data loading code\n",
        "traindir = data_dir / \"train\"\n",
        "valdir = data_dir / \"val\"\n",
        "testdir = data_dir / \"test\"\n",
        "\n",
        "normalize = transforms.Normalize(\n",
        "    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        ")\n",
        "\n",
        "train_dataset = datasets.ImageFolder(\n",
        "    traindir,\n",
        "    transforms.Compose(\n",
        "        [\n",
        "            transforms.RandomResizedCrop(224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ]\n",
        "    ),\n",
        ")\n",
        "actual_train_dataset, finetuning_dataset = train_dataset.train_test_split(test_size=0.1)\n",
        "\n",
        "test_dataset = datasets.ImageFolder(\n",
        "    testdir,\n",
        "    transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ]\n",
        "    ),\n",
        ")\n",
        "actual_test_dataset, val_dataset = train_dataset.train_test_split(test_size=0.1)\n",
        "\n",
        "kwargs = dict(\n",
        "    batch_size=batch_size,\n",
        "    num_workers=workers,\n",
        ")\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,  **kwargs\n",
        ")\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, **kwargs)"
      ],
      "metadata": {
        "id": "tH_MskXlA5DG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "8d212eb7-4105-44f3-bb0a-59e771398366"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-c88c4a1717cb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Data loading code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraindir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvaldir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtestdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    start_time = time.time()\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        # train\n",
        "        if weights == \"finetune\":\n",
        "            model.train()\n",
        "        elif weights == \"freeze\":\n",
        "            model.eval()\n",
        "        else:\n",
        "            assert False\n",
        "        for step, (images, target) in enumerate(\n",
        "            train_loader, start=epoch * len(train_loader)\n",
        "        ):\n",
        "            output = model(images.cuda(gpu, non_blocking=True))\n",
        "            loss = criterion(output, target.cuda(gpu, non_blocking=True))\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if step % print_freq == 0:\n",
        "                pg = optimizer.param_groups\n",
        "                lr_head = pg[0][\"lr\"]\n",
        "                lr_backbone = pg[1][\"lr\"] if len(pg) == 2 else 0\n",
        "                stats = dict(\n",
        "                    epoch=epoch,\n",
        "                    step=step,\n",
        "                    lr_backbone=lr_backbone,\n",
        "                    lr_head=lr_head,\n",
        "                    loss=loss.item(),\n",
        "                    time=int(time.time() - start_time),\n",
        "                )\n",
        "                print(json.dumps(stats))\n",
        "                print(json.dumps(stats), file=stats_file)\n",
        "                \n",
        "\n",
        "        # evaluate\n",
        "        model.eval()\n",
        "        if rank == 0:\n",
        "            top1 = AverageMeter(\"Acc@1\")\n",
        "            top5 = AverageMeter(\"Acc@5\")\n",
        "            with torch.no_grad():\n",
        "                for images, target in val_loader:\n",
        "                    output = model(images.cuda())\n",
        "                    acc1, acc5 = accuracy(\n",
        "                        output, target.cuda(), topk=(1, 5)\n",
        "                    )\n",
        "                    top1.update(acc1[0].item(), images.size(0))\n",
        "                    top5.update(acc5[0].item(), images.size(0))\n",
        "            best_acc.top1 = max(best_acc.top1, top1.avg)\n",
        "            best_acc.top5 = max(best_acc.top5, top5.avg)\n",
        "            stats = dict(\n",
        "                epoch=epoch,\n",
        "                acc1=top1.avg,\n",
        "                acc5=top5.avg,\n",
        "                best_acc1=best_acc.top1,\n",
        "                best_acc5=best_acc.top5,\n",
        "            )\n",
        "            print(json.dumps(stats))\n",
        "            print(json.dumps(stats), file=open(stats_file, 'r'))\n",
        "        if rank == 0:\n",
        "            state = dict(\n",
        "                epoch=epoch + 1,\n",
        "                best_acc=best_acc,\n",
        "                model=model.state_dict(),\n",
        "                optimizer=optimizer.state_dict(),\n",
        "                scheduler=scheduler.state_dict(),\n",
        "            )\n",
        "            torch.save(state, exp_dir / \"checkpoint.pth\")\n",
        "\n",
        "\n",
        "# def handle_sigusr1(signum, frame):\n",
        "#     os.system(f'scontrol requeue {os.getenv(\"SLURM_JOB_ID\")}')\n",
        "#     exit()\n",
        "\n",
        "\n",
        "# def handle_sigterm(signum, frame):\n",
        "#     pass\n",
        "\n",
        "\n",
        "\n",
        "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
        "\n",
        "# All rights reserved.\n",
        "\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "\n",
        "\n",
        "   "
      ],
      "metadata": {
        "id": "VBg0Kwbg-_Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "id": "1YT2RadrHnLW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}